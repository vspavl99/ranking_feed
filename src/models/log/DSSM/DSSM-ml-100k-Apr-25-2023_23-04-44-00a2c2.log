Tue 25 Apr 2023 23:04:44 INFO  ['C:\\Users\\vpavl\\PycharmProjects\\ranking-feed\\src\\models\\test.py']
Tue 25 Apr 2023 23:04:44 INFO  
General Hyper Parameters:
gpu_id = 0
use_gpu = True
seed = 2020
state = INFO
reproducibility = True
data_path = C:\Users\vpavl\PycharmProjects\ranking-feed\RecBole\recbole\config\../dataset_example/ml-100k
checkpoint_dir = saved
show_progress = True
save_dataset = False
dataset_save_path = None
save_dataloaders = False
dataloaders_save_path = None
log_wandb = False

Training Hyper Parameters:
epochs = 300
train_batch_size = 2048
learner = adam
learning_rate = 0.001
train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}
eval_step = 1
stopping_step = 10
clip_grad_norm = None
weight_decay = 0.0
loss_decimal_place = 4

Evaluation Hyper Parameters:
eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': None, 'mode': {'valid': 'labeled', 'test': 'labeled'}}
repeatable = False
metrics = ['AUC', 'LogLoss']
topk = [10]
valid_metric = AUC
valid_metric_bigger = True
eval_batch_size = 4096
metric_decimal_place = 4

Dataset Hyper Parameters:
field_separator = 	
seq_separator =  
USER_ID_FIELD = user_id
ITEM_ID_FIELD = item_id
RATING_FIELD = rating
TIME_FIELD = timestamp
seq_len = None
LABEL_FIELD = label
threshold = {'rating': 4}
NEG_PREFIX = neg_
load_col = {'inter': ['user_id', 'item_id', 'rating', 'timestamp'], 'user': ['user_id', 'age', 'gender', 'occupation'], 'item': ['item_id', 'release_year', 'class']}
unload_col = None
unused_col = None
additional_feat_suffix = None
rm_dup_inter = None
val_interval = None
filter_inter_by_user_or_item = True
user_inter_num_interval = None
item_inter_num_interval = None
alias_of_user_id = None
alias_of_item_id = None
alias_of_entity_id = None
alias_of_relation_id = None
preload_weight = None
normalize_field = None
normalize_all = True
ITEM_LIST_LENGTH_FIELD = item_length
LIST_SUFFIX = _list
MAX_ITEM_LIST_LENGTH = 50
POSITION_FIELD = position_id
HEAD_ENTITY_ID_FIELD = head_id
TAIL_ENTITY_ID_FIELD = tail_id
RELATION_ID_FIELD = relation_id
ENTITY_ID_FIELD = entity_id
kg_reverse_r = False
entity_kg_num_interval = None
relation_kg_num_interval = None
benchmark_filename = None

Other Hyper Parameters: 
worker = 0
wandb_project = recbole
shuffle = True
require_pow = False
enable_amp = False
enable_scaler = False
transform = None
embedding_size = 10
mlp_hidden_size = [256, 256, 256]
dropout_prob = 0.3
double_tower = True
numerical_features = []
discretization = None
MODEL_TYPE = ModelType.CONTEXT
MODEL_INPUT_TYPE = InputType.POINTWISE
eval_type = EvaluatorType.VALUE
single_spec = True
local_rank = 0
device = cpu
valid_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}
test_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}


Tue 25 Apr 2023 23:04:45 INFO  ml-100k
The number of users: 944
Average actions of users: 106.04453870625663
The number of items: 1683
Average actions of items: 59.45303210463734
The number of inters: 100000
The sparsity of the dataset: 93.70575143257098%
Remain Fields: ['user_id', 'item_id', 'timestamp', 'age', 'gender', 'occupation', 'release_year', 'class', 'label']
Tue 25 Apr 2023 23:04:45 INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]
Tue 25 Apr 2023 23:04:45 INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': None, 'mode': {'valid': 'labeled', 'test': 'labeled'}}]
Tue 25 Apr 2023 23:04:45 INFO  DSSM(
  (token_embedding_table): FMEmbedding(
    (embedding): Embedding(2788, 10)
  )
  (token_seq_embedding_table): ModuleList(
    (0): Embedding(20, 10)
  )
  (first_order_linear): FMFirstOrderLinear(
    (token_embedding_table): FMEmbedding(
      (embedding): Embedding(2788, 1)
    )
    (token_seq_embedding_table): ModuleList(
      (0): Embedding(20, 1)
    )
  )
  (user_mlp_layers): MLPLayers(
    (mlp_layers): Sequential(
      (0): Dropout(p=0.3, inplace=False)
      (1): Linear(in_features=40, out_features=256, bias=True)
      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): Tanh()
      (4): Dropout(p=0.3, inplace=False)
      (5): Linear(in_features=256, out_features=256, bias=True)
      (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (7): Tanh()
      (8): Dropout(p=0.3, inplace=False)
      (9): Linear(in_features=256, out_features=256, bias=True)
      (10): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (11): Tanh()
    )
  )
  (item_mlp_layers): MLPLayers(
    (mlp_layers): Sequential(
      (0): Dropout(p=0.3, inplace=False)
      (1): Linear(in_features=30, out_features=256, bias=True)
      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): Tanh()
      (4): Dropout(p=0.3, inplace=False)
      (5): Linear(in_features=256, out_features=256, bias=True)
      (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (7): Tanh()
      (8): Dropout(p=0.3, inplace=False)
      (9): Linear(in_features=256, out_features=256, bias=True)
      (10): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (11): Tanh()
    )
  )
  (loss): BCEWithLogitsLoss()
  (sigmoid): Sigmoid()
)
Trainable parameters: 315561
Tue 25 Apr 2023 23:04:45 INFO  FLOPs: 286328.0
Tue 25 Apr 2023 23:04:52 INFO  epoch 0 training [time: 6.61s, train loss: 27.7533]
Tue 25 Apr 2023 23:04:52 INFO  epoch 0 evaluating [time: 0.21s, valid_score: 0.553700]
Tue 25 Apr 2023 23:04:52 INFO  valid result: 
auc : 0.5537    logloss : 0.6886
Tue 25 Apr 2023 23:04:52 INFO  Saving current: saved\DSSM-Apr-25-2023_23-04-45.pth
Tue 25 Apr 2023 23:04:57 INFO  epoch 1 training [time: 5.55s, train loss: 27.6640]
Tue 25 Apr 2023 23:04:58 INFO  epoch 1 evaluating [time: 0.24s, valid_score: 0.560000]
Tue 25 Apr 2023 23:04:58 INFO  valid result: 
auc : 0.56    logloss : 0.6876
Tue 25 Apr 2023 23:04:58 INFO  Saving current: saved\DSSM-Apr-25-2023_23-04-45.pth
Tue 25 Apr 2023 23:05:03 INFO  epoch 2 training [time: 5.72s, train loss: 27.4886]
Tue 25 Apr 2023 23:05:03 INFO  epoch 2 evaluating [time: 0.20s, valid_score: 0.585100]
Tue 25 Apr 2023 23:05:03 INFO  valid result: 
auc : 0.5851    logloss : 0.6816
Tue 25 Apr 2023 23:05:03 INFO  Saving current: saved\DSSM-Apr-25-2023_23-04-45.pth
Tue 25 Apr 2023 23:05:09 INFO  epoch 3 training [time: 5.62s, train loss: 27.1485]
Tue 25 Apr 2023 23:05:09 INFO  epoch 3 evaluating [time: 0.19s, valid_score: 0.628200]
Tue 25 Apr 2023 23:05:09 INFO  valid result: 
auc : 0.6282    logloss : 0.6674
Tue 25 Apr 2023 23:05:09 INFO  Saving current: saved\DSSM-Apr-25-2023_23-04-45.pth
Tue 25 Apr 2023 23:05:15 INFO  epoch 4 training [time: 5.52s, train loss: 26.4460]
Tue 25 Apr 2023 23:05:15 INFO  epoch 4 evaluating [time: 0.21s, valid_score: 0.670200]
Tue 25 Apr 2023 23:05:15 INFO  valid result: 
auc : 0.6702    logloss : 0.649
Tue 25 Apr 2023 23:05:15 INFO  Saving current: saved\DSSM-Apr-25-2023_23-04-45.pth
Tue 25 Apr 2023 23:05:21 INFO  epoch 5 training [time: 5.65s, train loss: 25.6535]
Tue 25 Apr 2023 23:05:21 INFO  epoch 5 evaluating [time: 0.19s, valid_score: 0.694200]
Tue 25 Apr 2023 23:05:21 INFO  valid result: 
auc : 0.6942    logloss : 0.636
Tue 25 Apr 2023 23:05:21 INFO  Saving current: saved\DSSM-Apr-25-2023_23-04-45.pth
Tue 25 Apr 2023 23:05:26 INFO  epoch 6 training [time: 5.53s, train loss: 25.0432]
Tue 25 Apr 2023 23:05:27 INFO  epoch 6 evaluating [time: 0.19s, valid_score: 0.705700]
Tue 25 Apr 2023 23:05:27 INFO  valid result: 
auc : 0.7057    logloss : 0.6287
Tue 25 Apr 2023 23:05:27 INFO  Saving current: saved\DSSM-Apr-25-2023_23-04-45.pth
Tue 25 Apr 2023 23:05:32 INFO  epoch 7 training [time: 5.46s, train loss: 24.6853]
Tue 25 Apr 2023 23:05:32 INFO  epoch 7 evaluating [time: 0.20s, valid_score: 0.715200]
Tue 25 Apr 2023 23:05:32 INFO  valid result: 
auc : 0.7152    logloss : 0.6222
Tue 25 Apr 2023 23:05:32 INFO  Saving current: saved\DSSM-Apr-25-2023_23-04-45.pth
Tue 25 Apr 2023 23:05:38 INFO  epoch 8 training [time: 5.42s, train loss: 24.3398]
Tue 25 Apr 2023 23:05:38 INFO  epoch 8 evaluating [time: 0.19s, valid_score: 0.723700]
Tue 25 Apr 2023 23:05:38 INFO  valid result: 
auc : 0.7237    logloss : 0.6168
Tue 25 Apr 2023 23:05:38 INFO  Saving current: saved\DSSM-Apr-25-2023_23-04-45.pth
Tue 25 Apr 2023 23:05:44 INFO  epoch 9 training [time: 5.79s, train loss: 24.1106]
Tue 25 Apr 2023 23:05:44 INFO  epoch 9 evaluating [time: 0.24s, valid_score: 0.729700]
Tue 25 Apr 2023 23:05:44 INFO  valid result: 
auc : 0.7297    logloss : 0.6127
Tue 25 Apr 2023 23:05:44 INFO  Saving current: saved\DSSM-Apr-25-2023_23-04-45.pth
Tue 25 Apr 2023 23:05:50 INFO  epoch 10 training [time: 6.40s, train loss: 23.9225]
Tue 25 Apr 2023 23:05:51 INFO  epoch 10 evaluating [time: 0.19s, valid_score: 0.736800]
Tue 25 Apr 2023 23:05:51 INFO  valid result: 
auc : 0.7368    logloss : 0.6086
Tue 25 Apr 2023 23:05:51 INFO  Saving current: saved\DSSM-Apr-25-2023_23-04-45.pth
Tue 25 Apr 2023 23:05:56 INFO  epoch 11 training [time: 5.59s, train loss: 23.7924]
Tue 25 Apr 2023 23:05:56 INFO  epoch 11 evaluating [time: 0.20s, valid_score: 0.740600]
Tue 25 Apr 2023 23:05:56 INFO  valid result: 
auc : 0.7406    logloss : 0.606
Tue 25 Apr 2023 23:05:56 INFO  Saving current: saved\DSSM-Apr-25-2023_23-04-45.pth
Tue 25 Apr 2023 23:06:02 INFO  epoch 12 training [time: 5.31s, train loss: 23.6469]
Tue 25 Apr 2023 23:06:02 INFO  epoch 12 evaluating [time: 0.20s, valid_score: 0.744400]
Tue 25 Apr 2023 23:06:02 INFO  valid result: 
auc : 0.7444    logloss : 0.6037
Tue 25 Apr 2023 23:06:02 INFO  Saving current: saved\DSSM-Apr-25-2023_23-04-45.pth
